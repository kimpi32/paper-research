import type { Paper } from "./types";

export const newPapers: Record<string, Paper[]> = {
  "multimodal": [
    {
      id: "vilbert",
      title: "ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks",
      titleKo: "ViLBERT: 비전-언어 과제를 위한 과제 비의존적 시각언어 표현 사전학습",
      authors: ["Jiasen Lu", "Dhruv Batra", "Devi Parikh", "Stefan Lee"],
      year: 2019,
      venue: "NeurIPS 2019",
      venueType: "neurips",
      arxivUrl: "https://arxiv.org/abs/1908.02265",
      tags: [],
      status: "complete",
      citations: "3,000+",
    },
    {
      id: "dall-e",
      title: "Zero-Shot Text-to-Image Generation",
      titleKo: "제로샷 텍스트-이미지 생성",
      authors: ["Aditya Ramesh", "Mikhail Pavlov", "Gabriel Goh", "et al."],
      year: 2021,
      venue: "ICML 2021",
      venueType: "icml",
      arxivUrl: "https://arxiv.org/abs/2102.12092",
      tags: [],
      status: "complete",
      citations: "5,000+",
    },
    {
      id: "align",
      title: "Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision",
      titleKo: "노이즈가 포함된 텍스트 감독을 활용한 시각 및 비전-언어 표현 학습의 스케일링",
      authors: ["Chao Jia", "Yinfei Yang", "Ye Xia", "et al."],
      year: 2021,
      venue: "ICML 2021",
      venueType: "icml",
      arxivUrl: "https://arxiv.org/abs/2102.05918",
      tags: [],
      status: "complete",
      citations: "3,000+",
    },
    {
      id: "blip2",
      title: "BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models",
      titleKo: "BLIP-2: 동결된 이미지 인코더와 대규모 언어 모델을 활용한 언어-이미지 사전학습 부트스트래핑",
      authors: ["Junnan Li", "Dongxu Li", "Silvio Savarese", "Steven Hoi"],
      year: 2023,
      venue: "ICML 2023",
      venueType: "icml",
      arxivUrl: "https://arxiv.org/abs/2301.12597",
      tags: [],
      status: "complete",
      citations: "5,000+",
    },
    {
      id: "cogvlm",
      title: "CogVLM: Visual Expert for Pretrained Language Models",
      titleKo: "CogVLM: 사전학습된 언어 모델을 위한 시각 전문가",
      authors: ["Weihan Wang", "Qingsong Lv", "Wenmeng Yu", "et al."],
      year: 2023,
      venue: "arXiv",
      venueType: "arxiv",
      arxivUrl: "https://arxiv.org/abs/2311.03079",
      tags: [],
      status: "complete",
      citations: "1,000+",
    },
    {
      id: "gemini",
      title: "Gemini: A Family of Highly Capable Multimodal Models",
      titleKo: "Gemini: 고성능 멀티모달 모델 패밀리",
      authors: ["Gemini Team", "Google DeepMind"],
      year: 2024,
      venue: "arXiv",
      venueType: "arxiv",
      arxivUrl: "https://arxiv.org/abs/2312.11805",
      tags: [],
      status: "complete",
      citations: "3,000+",
    },
    {
      id: "internvl",
      title: "InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks",
      titleKo: "InternVL: 범용 시각-언어 과제를 위한 비전 파운데이션 모델 스케일링 및 정렬",
      authors: ["Zhe Chen", "Jiannan Wu", "Wenhai Wang", "et al."],
      year: 2024,
      venue: "CVPR 2024",
      venueType: "cvpr",
      arxivUrl: "https://arxiv.org/abs/2312.14238",
      tags: [],
      status: "complete",
      citations: "1,000+",
    },
  ],
  "audio": [
    {
      id: "tacotron2",
      title: "Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions",
      titleKo: "멜 스펙트로그램 예측 기반 WaveNet 조건부 자연 TTS 합성",
      authors: ["Jonathan Shen", "Ruoming Pang", "Ron J. Weiss", "et al."],
      year: 2018,
      venue: "ICASSP 2018",
      venueType: "other",
      arxivUrl: "https://arxiv.org/abs/1712.05884",
      tags: [],
      status: "complete",
      citations: "5,000+",
    },
    {
      id: "hubert",
      title: "HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units",
      titleKo: "HuBERT: 은닉 유닛의 마스크 예측을 통한 자기지도 음성 표현 학습",
      authors: ["Wei-Ning Hsu", "Benjamin Bolte", "Yao-Hung Hubert Tsai", "et al."],
      year: 2021,
      venue: "IEEE/ACM TASLP 2021",
      venueType: "other",
      arxivUrl: "https://arxiv.org/abs/2106.07447",
      tags: [],
      status: "complete",
      citations: "3,000+",
    },
    {
      id: "soundstream",
      title: "SoundStream: An End-to-End Neural Audio Codec",
      titleKo: "SoundStream: 엔드투엔드 신경 오디오 코덱",
      authors: ["Neil Zeghidour", "Alejandro Luebs", "Ahmed Omran", "et al."],
      year: 2021,
      venue: "IEEE/ACM TASLP 2022",
      venueType: "other",
      arxivUrl: "https://arxiv.org/abs/2107.03312",
      tags: [],
      status: "complete",
      citations: "1,500+",
    },
    {
      id: "audiolm",
      title: "AudioLM: a Language Modeling Approach to Audio Generation",
      titleKo: "AudioLM: 오디오 생성을 위한 언어 모델링 접근법",
      authors: ["Zalán Borsos", "Raphaël Marinier", "Damien Vincent", "et al."],
      year: 2022,
      venue: "IEEE/ACM TASLP 2023",
      venueType: "other",
      arxivUrl: "https://arxiv.org/abs/2209.03143",
      tags: [],
      status: "complete",
      citations: "1,000+",
    },
    {
      id: "encodec",
      title: "High Fidelity Neural Audio Compression",
      titleKo: "고충실도 신경 오디오 압축",
      authors: ["Alexandre Défossez", "Jade Copet", "Gabriel Synnaeve", "Yossi Adi"],
      year: 2022,
      venue: "arXiv",
      venueType: "arxiv",
      arxivUrl: "https://arxiv.org/abs/2210.13438",
      tags: [],
      status: "complete",
      citations: "1,500+",
    },
    {
      id: "musiclm",
      title: "MusicLM: Generating Music From Text",
      titleKo: "MusicLM: 텍스트로부터 음악 생성",
      authors: ["Andrea Agostinelli", "Timo I. Denk", "Zalán Borsos", "et al."],
      year: 2023,
      venue: "arXiv",
      venueType: "arxiv",
      arxivUrl: "https://arxiv.org/abs/2301.11325",
      tags: [],
      status: "complete",
      citations: "1,000+",
    },
    {
      id: "bark",
      title: "Bark: Text-Prompted Generative Audio Model",
      titleKo: "Bark: 텍스트 프롬프트 기반 생성 오디오 모델",
      authors: ["Suno AI"],
      year: 2023,
      venue: "GitHub / Suno AI",
      venueType: "other",
      conferenceUrl: "https://github.com/suno-ai/bark",
      tags: [],
      status: "complete",
      citations: "500+",
    },
  ],
  "representation": [
    {
      id: "moco",
      title: "Momentum Contrast for Unsupervised Visual Representation Learning",
      titleKo: "비지도 시각 표현 학습을 위한 모멘텀 대조",
      authors: ["Kaiming He", "Haoqi Fan", "Yuxin Wu", "et al."],
      year: 2019,
      venue: "CVPR 2020",
      venueType: "cvpr",
      arxivUrl: "https://arxiv.org/abs/1911.05722",
      tags: [],
      status: "complete",
      citations: "10,000+",
    },
    {
      id: "swav",
      title: "Unsupervised Learning of Visual Features by Contrasting Cluster Assignments",
      titleKo: "클러스터 할당 대조를 통한 비지도 시각 특징 학습",
      authors: ["Mathilde Caron", "Ishan Misra", "Julien Mairal", "et al."],
      year: 2020,
      venue: "NeurIPS 2020",
      venueType: "neurips",
      arxivUrl: "https://arxiv.org/abs/2006.09882",
      tags: [],
      status: "complete",
      citations: "4,000+",
    },
    {
      id: "beit",
      title: "BEiT: BERT Pre-Training of Image Transformers",
      titleKo: "BEiT: 이미지 트랜스포머의 BERT 사전학습",
      authors: ["Hangbo Bao", "Li Dong", "Songhao Piao", "Furu Wei"],
      year: 2021,
      venue: "ICLR 2022",
      venueType: "iclr",
      arxivUrl: "https://arxiv.org/abs/2106.08254",
      tags: [],
      status: "complete",
      citations: "3,000+",
    },
    {
      id: "data2vec",
      title: "data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language",
      titleKo: "data2vec: 음성, 비전, 언어에서의 자기지도 학습을 위한 범용 프레임워크",
      authors: ["Alexei Baevski", "Wei-Ning Hsu", "Qiantong Xu", "et al."],
      year: 2022,
      venue: "ICML 2022",
      venueType: "icml",
      arxivUrl: "https://arxiv.org/abs/2202.03555",
      tags: [],
      status: "complete",
      citations: "1,500+",
    },
    {
      id: "vicreg",
      title: "VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning",
      titleKo: "VICReg: 자기지도 학습을 위한 분산-불변성-공분산 정규화",
      authors: ["Adrien Bardes", "Jean Ponce", "Yann LeCun"],
      year: 2022,
      venue: "ICLR 2022",
      venueType: "iclr",
      arxivUrl: "https://arxiv.org/abs/2105.04906",
      tags: [],
      status: "complete",
      citations: "1,500+",
    },
    {
      id: "dinov2",
      title: "DINOv2: Learning Robust Visual Features without Supervision",
      titleKo: "DINOv2: 감독 없이 강건한 시각 특징 학습",
      authors: ["Maxime Oquab", "Timothée Darcet", "Théo Moutakanni", "et al."],
      year: 2023,
      venue: "arXiv",
      venueType: "arxiv",
      arxivUrl: "https://arxiv.org/abs/2304.07193",
      tags: [],
      status: "complete",
      citations: "2,000+",
    },
  ],
};
